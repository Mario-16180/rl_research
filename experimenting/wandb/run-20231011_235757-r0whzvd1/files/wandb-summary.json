{"train/step": 129617, "train/training_reward": 0.0, "train/training_episode": 1089, "train/loss": 2.624915849149942e+30, "train/squared_norm_gradients": Infinity, "train/action_taken": 8, "train/epsilon": 0.050002207885244024, "train/replay_buffer_#ofexperiences": 134617, "train/learning_rate": 0.125, "_timestamp": 1697101522.423383, "_runtime": 47244.58788394928, "_step": 139976, "train/reward_eval_0": 0.0, "train/reward_eval_1": 0.0, "train/reward_eval_2": 0.0, "train/reward_eval_3": 0.0, "train/reward_eval_4": 0.0, "train/reward_eval_5": 0.0, "train/reward_eval_6": 0.0, "train/reward_eval_7": 0.0, "train/reward_eval_8": 0.0, "train/reward_eval_9": 0.0, "train/reward_eval_10": 0.0, "train/reward_eval_11": 0.0, "train/reward_eval_12": 0.0, "train/reward_eval_13": 0.0, "train/reward_eval_14": 0.0, "train/reward_eval_15": 0.0, "train/reward_eval_16": 0.0, "train/reward_eval_17": 0.0, "train/reward_eval_18": 0.0, "train/reward_eval_19": 0.0, "_wandb": {"runtime": 47243}}