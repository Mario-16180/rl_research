wandb_version: 1

architecture:
  desc: null
  value: IMPALA_large_CNN
dataset:
  desc: null
  value: procgen:procgen-bossfight-v0
learning_rate:
  desc: null
  value: 0.5
episodes:
  desc: null
  value: 5000
batch_size:
  desc: null
  value: 64
gamma:
  desc: null
  value: 0.99
epsilon_start:
  desc: null
  value: 0.99
epsilon_decay:
  desc: null
  value: 10000
epsilon_min:
  desc: null
  value: 0.05
tau:
  desc: null
  value: 0.01
memory_length:
  desc: null
  value: 1000000
optimizer:
  desc: null
  value: "Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n\
    \    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach:\
    \ None\n    fused: None\n    lr: 0.5\n    maximize: False\n    weight_decay: 0\n\
    )"
criterion:
  desc: null
  value: MSELoss()
device:
  desc: null
  value: cuda
num_levels:
  desc: null
  value: 0
num_levels_eval:
  desc: null
  value: 20
background:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    python_version: 3.8.18
    cli_version: 0.15.11
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1697054277.835499
    t:
      1:
      - 1
      - 55
      2:
      - 1
      - 55
      3:
      - 7
      - 16
      - 23
      4: 3.8.18
      5: 0.15.11
      8:
      - 5
      13: linux-x86_64
    m:
    - 1: train/step
      6:
      - 3
    - 1: train/training_reward
      5: 1
      6:
      - 1
    - 1: train/training_episode
      5: 1
      6:
      - 1
    - 1: train/loss
      5: 1
      6:
      - 1
    - 1: train/squared_norm_gradients
      5: 1
      6:
      - 1
    - 1: train/action_taken
      5: 1
      6:
      - 1
    - 1: train/epsilon
      5: 1
      6:
      - 1
    - 1: train/replay_buffer_#ofexperiences
      5: 1
      6:
      - 1
    - 1: train/learning_rate
      5: 1
      6:
      - 1
    - 1: train/reward_eval_0
      5: 1
      6:
      - 1
    - 1: train/reward_eval_1
      5: 1
      6:
      - 1
    - 1: train/reward_eval_2
      5: 1
      6:
      - 1
    - 1: train/reward_eval_3
      5: 1
      6:
      - 1
    - 1: train/reward_eval_4
      5: 1
      6:
      - 1
    - 1: train/reward_eval_5
      5: 1
      6:
      - 1
    - 1: train/reward_eval_6
      5: 1
      6:
      - 1
    - 1: train/reward_eval_7
      5: 1
      6:
      - 1
    - 1: train/reward_eval_8
      5: 1
      6:
      - 1
    - 1: train/reward_eval_9
      5: 1
      6:
      - 1
    - 1: train/reward_eval_10
      5: 1
      6:
      - 1
    - 1: train/reward_eval_11
      5: 1
      6:
      - 1
    - 1: train/reward_eval_12
      5: 1
      6:
      - 1
    - 1: train/reward_eval_13
      5: 1
      6:
      - 1
    - 1: train/reward_eval_14
      5: 1
      6:
      - 1
    - 1: train/reward_eval_15
      5: 1
      6:
      - 1
    - 1: train/reward_eval_16
      5: 1
      6:
      - 1
    - 1: train/reward_eval_17
      5: 1
      6:
      - 1
    - 1: train/reward_eval_18
      5: 1
      6:
      - 1
    - 1: train/reward_eval_19
      5: 1
      6:
      - 1
