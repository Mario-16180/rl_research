{"train/step": 249, "train/training_reward": 0.0, "train/training_episode": 4, "train/loss": 5.103901960382748e+29, "train/squared_norm_gradients": Infinity, "train/action_taken": 4, "train/epsilon": 0.9669746939071429, "train/replay_buffer_#ofexperiences": 5249, "train/learning_rate": 0.5, "_timestamp": 1697054190.803728, "_runtime": 92.35850119590759, "_step": 268, "train/reward_eval_0": 0.0, "train/reward_eval_1": 0.0, "train/reward_eval_2": 0.0, "train/reward_eval_3": 0.0, "train/reward_eval_4": 0.0, "train/reward_eval_5": 0.0, "train/reward_eval_6": 0.0, "train/reward_eval_7": 0.0, "train/reward_eval_8": 0.0, "train/reward_eval_9": 0.0, "train/reward_eval_10": 0.0, "train/reward_eval_11": 0.0, "train/reward_eval_12": 0.0, "train/reward_eval_13": 0.0, "train/reward_eval_14": 0.0, "train/reward_eval_15": 0.0, "train/reward_eval_16": 0.0, "train/reward_eval_17": 0.0, "train/reward_eval_18": 0.0, "train/reward_eval_19": 0.0, "_wandb": {"runtime": 91}}