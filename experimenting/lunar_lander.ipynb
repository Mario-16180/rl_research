{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "from models.lunar_lander_dqn_architecture import lunar_lander_mlp\n",
    "from rl_utils.stack_frames import stacked_frames_class\n",
    "from rl_utils.replay_buffer import memory\n",
    "from rl_utils.replay_buffer import memory_with_curriculum\n",
    "from rl_utils.optimization import perform_optimization_step\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.device(\"cuda:\"+gpu if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('BipedalWalker-v3')\n",
    "obs = env.reset(seed=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.7471273e-03,  2.6607242e-06, -3.4697267e-04, -1.6000018e-02,\n",
       "        9.2234910e-02,  8.0548920e-04,  8.6006725e-01,  7.6285080e-04,\n",
       "        1.0000000e+00,  3.2617871e-02,  8.0543885e-04,  8.5366613e-01,\n",
       "       -5.4804940e-04,  1.0000000e+00,  4.4081384e-01,  4.4581994e-01,\n",
       "        4.6142259e-01,  4.8954999e-01,  5.3410256e-01,  6.0246080e-01,\n",
       "        7.0914859e-01,  8.8593149e-01,  1.0000000e+00,  1.0000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lunar_lander_mlp(env, 128, 64).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading saved model\n",
    "weights = torch.load(\"models/trained_models/bright-cloud-72LunarLander-v2.pt\")\n",
    "model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: swrast\n",
      "/home/mario.cantero/.conda/envs/rl_research/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward: 194.82545354621797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: cannot open shared object file: No such file or directory (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: swrast\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m done:\n\u001b[1;32m     10\u001b[0m     action, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mselect_action(env, obs, \u001b[39m0.01\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m1\u001b[39m, device)\n\u001b[0;32m---> 11\u001b[0m     obs, reward, done, _, info  \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     12\u001b[0m     reward_accum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[1;32m     13\u001b[0m     env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/.conda/envs/rl_research/lib/python3.8/site-packages/gym/wrappers/time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[1;32m     40\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[0;32m~/.conda/envs/rl_research/lib/python3.8/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/.conda/envs/rl_research/lib/python3.8/site-packages/gym/wrappers/env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[1;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[0;32m~/.conda/envs/rl_research/lib/python3.8/site-packages/gym/envs/box2d/lunar_lander.py:599\u001b[0m, in \u001b[0;36mLunarLander.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    596\u001b[0m     reward \u001b[39m=\u001b[39m \u001b[39m+\u001b[39m\u001b[39m100\u001b[39m\n\u001b[1;32m    598\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrender_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 599\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrender()\n\u001b[1;32m    600\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(state, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32), reward, terminated, \u001b[39mFalse\u001b[39;00m, {}\n",
      "File \u001b[0;32m~/.conda/envs/rl_research/lib/python3.8/site-packages/gym/envs/box2d/lunar_lander.py:709\u001b[0m, in \u001b[0;36mLunarLander.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscreen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscreen\u001b[39m.\u001b[39mblit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msurf, (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m))\n\u001b[0;32m--> 709\u001b[0m pygame\u001b[39m.\u001b[39;49mevent\u001b[39m.\u001b[39;49mpump()\n\u001b[1;32m    710\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclock\u001b[39m.\u001b[39mtick(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata[\u001b[39m\"\u001b[39m\u001b[39mrender_fps\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    711\u001b[0m pygame\u001b[39m.\u001b[39mdisplay\u001b[39m.\u001b[39mflip()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    # USing thee environment with random actions\n",
    "    env = gym.make('LunarLander-v2', render_mode='human')\n",
    "    obs = env.reset()[0]\n",
    "    rewards = []\n",
    "    done = False\n",
    "    lengths = []\n",
    "    reward_accum = 0\n",
    "    while not done:\n",
    "        action, _ = model.select_action(env, obs, 0.01, 1, 0.01, 1, device)\n",
    "        obs, reward, done, _, info  = env.step(action)\n",
    "        reward_accum += reward\n",
    "        env.render()\n",
    "    print(f\"Episode reward: {reward_accum}\")\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.00270958,  1.4030491 , -0.27446315, -0.34982306,  0.00314648,\n",
       "         0.06216995,  0.        ,  0.        ], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b,c ,d, e = env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02720795,  1.3891824 ,  0.68803257, -0.28137437, -0.03099762,\n",
       "       -0.15412304,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.9374373 ,  0.16288441, -1.2419778 , -0.06932734,  0.79287654,\n",
       "       -0.63573176,  0.        ,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "action, eps = model.select_action(env, obs, 0.1, 1, 0.1, 1, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
